{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../input/train.csv\", names=['Store','Dept','Date','weeklySales','isHoliday'],sep=',', header=0)\n",
    "features = pd.read_csv(\"../input/features.csv\",sep=',', header=0,\n",
    "                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n",
    "                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\n",
    "stores = pd.read_csv(\"../input/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\n",
    "dataset = dataset.merge(stores, how='left').merge(features, how='left')\n",
    "\n",
    "# dataset[\"nextWeekHoliday\"] = dataset[\"isHoliday\"].shift(-1).fillna(False)\n",
    "# dataset[\"next2WeekHoliday\"] = dataset[\"isHoliday\"].shift(-2).fillna(False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53ed17a3087c8d1b282d852e55a4843e23136ec6"
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5d0f48bb70f7676dc1268eadcfac31703a852ea"
   },
   "outputs": [],
   "source": [
    "def scatter(dataset, column):\n",
    "    plt.figure()\n",
    "    plt.scatter(dataset[column] , dataset['weeklySales'])\n",
    "    plt.ylabel('weeklySales')\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24f3db6eaa3103816f2316c3c52480124a888a96"
   },
   "outputs": [],
   "source": [
    "scatter(dataset, 'Fuel_Price')\n",
    "scatter(dataset, 'Size')\n",
    "scatter(dataset, 'CPI')\n",
    "scatter(dataset, 'Type')\n",
    "scatter(dataset, 'isHoliday')\n",
    "scatter(dataset, 'Unemployment')\n",
    "scatter(dataset, 'Temperature')\n",
    "scatter(dataset, 'Store')\n",
    "scatter(dataset, 'Dept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7de400728cdc665aefedd7ba506cffbbf6dfe87d"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 14))\n",
    "corr = dataset.corr()\n",
    "c = plt.pcolor(corr)\n",
    "plt.yticks(np.arange(0.5, len(corr.index), 1), corr.index)\n",
    "plt.xticks(np.arange(0.5, len(corr.columns), 1), corr.columns)\n",
    "fig.colorbar(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e0904eb6e8a0ef0e8ed4d6e22e2f94c4679eb29"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, vars=['weeklySales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5a2f040da4240cb077bdb887f999e0eab87dc45"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataset.fillna(0), vars=['weeklySales', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ca7ce44c053e3724d7adf9f3fb91e1ee73dbfbe"
   },
   "outputs": [],
   "source": [
    "for name, group in dataset.groupby([\"Store\", \"Dept\"]):\n",
    "    plt.title(name)\n",
    "    plt.scatter(range(len(group)), group[\"weeklySales\"])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45bb9a93aa88a169dae9dc805525a1f56f2afeec"
   },
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1586a44ad77b30ff62ac07810796b391bc1096de"
   },
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=[\"Type\"])\n",
    "dataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\n",
    "dataset['Month'] = pd.to_datetime(dataset['Date']).dt.month\n",
    "dataset = dataset.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "352d8fad9967d928067c9623ff8cb73f20748689"
   },
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aeff66f6968ab4744e8b4c8f5cb3da0b78427bc4"
   },
   "outputs": [],
   "source": [
    "def knn():\n",
    "    knn = KNeighborsRegressor(n_neighbors=10)\n",
    "    return knn\n",
    "\n",
    "def extraTreesRegressor():\n",
    "    clf = ExtraTreesRegressor(n_estimators=100,max_features='auto', verbose=1, n_jobs=1)\n",
    "    return clf\n",
    "\n",
    "def randomForestRegressor():\n",
    "    clf = RandomForestRegressor(n_estimators=100,max_features='log2', verbose=1)\n",
    "    return clf\n",
    "\n",
    "def svm():\n",
    "    clf = SVR(kernel='rbf', gamma='auto')\n",
    "    return clf\n",
    "\n",
    "def nn():\n",
    "    clf = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', verbose=3)\n",
    "    return clf\n",
    "\n",
    "def predict_(m, test_x):\n",
    "    return pd.Series(m.predict(test_x))\n",
    "\n",
    "def model_():\n",
    "#     return knn()\n",
    "    return extraTreesRegressor()\n",
    "#     return svm()\n",
    "#     return nn()\n",
    "#     return randomForestRegressor()    \n",
    "\n",
    "def train_(train_x, train_y):\n",
    "    m = model_()\n",
    "    m.fit(train_x, train_y)\n",
    "    return m\n",
    "\n",
    "def train_and_predict(train_x, train_y, test_x):\n",
    "    m = train_(train_x, train_y)\n",
    "    return predict_(m, test_x), m\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6362f82c58ab4d3ea68ff5c229d9fcea708cb40"
   },
   "outputs": [],
   "source": [
    "def calculate_error(test_y, predicted, weights):\n",
    "    return mean_absolute_error(test_y, predicted, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "026ef5e7777cfbcf916149b4fe0166fd9d68e9a7"
   },
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8617c90dd3fc8785998e9f70791cda8bc4be8a8b"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "splited = []\n",
    "# dataset2 = dataset.copy()\n",
    "for name, group in dataset.groupby([\"Store\", \"Dept\"]):\n",
    "    group = group.reset_index(drop=True)\n",
    "    trains_x = []\n",
    "    trains_y = []\n",
    "    tests_x = []\n",
    "    tests_y = []\n",
    "    if group.shape[0] <= 5:\n",
    "        f = np.array(range(5))\n",
    "        np.random.shuffle(f)\n",
    "        group['fold'] = f[:group.shape[0]]\n",
    "        continue\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(group):\n",
    "        group.loc[test_index, 'fold'] = fold\n",
    "        fold += 1\n",
    "    splited.append(group)\n",
    "\n",
    "splited = pd.concat(splited).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26822d7b261448591fc7434cfee6d2a2f91ac959"
   },
   "outputs": [],
   "source": [
    "splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30cdc19c8599a1aef105d5c80ce90cf8bea35950"
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "error_cv = 0\n",
    "best_error = np.iinfo(np.int32).max\n",
    "for fold in range(5):\n",
    "    dataset_train = splited.loc[splited['fold'] != fold]\n",
    "    dataset_test = splited.loc[splited['fold'] == fold]\n",
    "    train_y = dataset_train['weeklySales']\n",
    "    train_x = dataset_train.drop(columns=['weeklySales', 'fold'])\n",
    "    test_y = dataset_test['weeklySales']\n",
    "    test_x = dataset_test.drop(columns=['weeklySales', 'fold'])\n",
    "    print(dataset_train.shape, dataset_test.shape)\n",
    "    predicted, model = train_and_predict(train_x, train_y, test_x)\n",
    "    weights = test_x['isHoliday'].replace(True, 5).replace(False, 1)\n",
    "    error = calculate_error(test_y, predicted, weights)\n",
    "    error_cv += error\n",
    "    print(fold, error)\n",
    "    if error < best_error:\n",
    "        print('Find best model')\n",
    "        best_error = error\n",
    "        best_model = model\n",
    "error_cv /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c3a501047d0f11bebe024b9f2ada4af3972afcb"
   },
   "outputs": [],
   "source": [
    "error_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c2978bb15b4c85683965073b618c8434bf906ec"
   },
   "outputs": [],
   "source": [
    "best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9846b3805128195f4523e1a94b861ad6d9a76846"
   },
   "source": [
    "# Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dfabc7cecc08820d0bf51080b8372df1d28b5135"
   },
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(\"../input/test.csv\", names=['Store','Dept','Date','isHoliday'],sep=',', header=0)\n",
    "features = pd.read_csv(\"../input/features.csv\",sep=',', header=0,\n",
    "                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n",
    "                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\n",
    "stores = pd.read_csv(\"../input/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\n",
    "dataset_test = dataset_test.merge(stores, how='left').merge(features, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d00aba009ef6014dd59b246e598e662c75d70147"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c97ad94a99f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MarkDown1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MarkDown2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MarkDown3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MarkDown4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MarkDown5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MarkDown1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MarkDown2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MarkDown3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MarkDown4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MarkDown5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolumn_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_test = pd.get_dummies(dataset_test, columns=[\"Type\"])\n",
    "dataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\n",
    "dataset_test = dataset_test.fillna(0)\n",
    "column_date = dataset_test['Date']\n",
    "dataset_test['Month'] = pd.to_datetime(dataset_test['Date']).dt.month\n",
    "dataset_test = dataset_test.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c3e9b28cca52f2a65b0d23df9dae4fa9ed04d1d"
   },
   "outputs": [],
   "source": [
    "predicted_test = best_model.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11d17ed57d86542aaecfedbbd9e5eb70b3b57dc2"
   },
   "outputs": [],
   "source": [
    "dataset_test['weeklySales'] = predicted_test\n",
    "dataset_test['Date'] = column_date\n",
    "dataset_test['id'] = dataset_test['Store'].astype(str) + '_' +  dataset_test['Dept'].astype(str) + '_' +  dataset_test['Date'].astype(str)\n",
    "dataset_test = dataset_test[['id', 'weeklySales']]\n",
    "dataset_test = dataset_test.rename(columns={'id': 'Id', 'weeklySales': 'Weekly_Sales'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ef4f71be2fe8c6f037dacb33b37106f70f5dac9"
   },
   "outputs": [],
   "source": [
    "dataset_test.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
